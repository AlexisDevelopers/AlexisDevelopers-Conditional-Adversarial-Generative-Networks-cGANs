{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMjS2FPzfCcv"
      },
      "source": [
        "# Conditioned Adversarial Generative Networks (cGANs)\n",
        "---\n",
        "\n",
        "We will create a *generative conditional network* from which we can obtain images for each of the classes in the dataset. Once we have trained it, we visualize the generation of 3 images of the FROG class (üê∏) and 3 images of the HORSE class (üêé). **Given the complexity of the dataset and the low resolution of the images, it is normal to expect images where the generated object is not clearly identified.**\n",
        "\n",
        "<br>\n",
        "<img src='https://miro.medium.com/max/424/1*0hHJfc0V_Km_AgKkP892fw.png'>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7s7x1KaVU4p",
        "outputId": "e765e913-0ac8-448f-cb44-9b9886139a3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets.cifar10 import load_data\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# We load the CIFAR10 dataset into a variable.\n",
        "(X_train, Y_train), (X_test, Y_test) = load_data()\n",
        "\n",
        "# We One-Hot encode the output.\n",
        "Y_train = to_categorical(Y_train)\n",
        "Y_test  = to_categorical(Y_test)\n",
        "\n",
        "#train_gen = ImageDataGenerator(rescale=1/255).flow(X_train, Y_train)\n",
        "train_gen = ImageDataGenerator(rescale=1/255).flow(X_train.reshape(-1, 32, 32, 3), Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WyEA7M5IWOCt"
      },
      "outputs": [],
      "source": [
        "# Name of the classes ordered by the corresponding index.\n",
        "class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "mUTbHcsxV07b",
        "outputId": "0816d6c8-c3be-444d-c750-ee14953168ea"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfYklEQVR4nO2de4xd13Xev3XfM3eG8yI5fFoPilFEVzHtsrJTqY4S5yGrKGSjSWAVMAxUKdM0Bmw0RSC4QaM+gDpFbcN/FA7oSIgSuHbU2Iadwk2sKCmMAK1s6kVRUa0nKYoaPoYzw3ne51n9414GI2V/e4acmXvp7O8HDGZmr9nnrLvnrnvO3d9da5m7Qwjxd59cvx0QQvQGBbsQiaBgFyIRFOxCJIKCXYhEULALkQgKdrFhzMzN7JZ++yHiKNgTwcxOmdnP9tsP0T8U7AJmVui3D2LrUbAngJn9IYB3AfgTM1s0s9/s3no/YGZvAPgLM7vbzN58x7y/uRsws7yZfcbMXjWzBTN7ysz2B851l5mdMbO7e/DQxFWgYE8Ad/84gDcA/BN3HwLwWNf0UwBuA/AL6zjMvwZwP4B7AWwD8M8BLK/+AzO7B8BXAfxTd//fm+K82DR0+5Y2D7n7EgCY2Vp/+ysAftPdf9j9/bl32H8JwL8E8GF3P7mpXopNQVf2tDlzFX+7H8CrEfunATymQL9+UbCnQyi9cfXYEoDBK7+YWR7AjlX2MwAORI7/SwA+Ymaf2oiTYutQsKfDeQA3R+wvAaiY2T82syKA3wJQXmX/PQD/0cwOWoefMLOJVfa3AHwIwKfM7Nc223mxcRTs6fCfAfyWmc0B+MV3Gt39MoB/hU5Qn0XnSr96d/7z6GzsfRfAPICHAQy84xhvoBPwD5rZr2z+QxAbwVS8Qog00JVdiERQsAuRCAp2IRJBwS5EIvT0E3SFYs6L5Tyx8o1C/tmuyKe+IqZC5FHncvz1z8hrY2yTsxA5WT7H1gLI5SLz8txWKBTJnPB410otrVaL2rKszf3Ih4+ZJ+MAMFQdorZcZB17ucV8zfvZ1zJvzQ81/m3OvHEal6angzM3FOzdz0J/EZ1ny++5+2djf18s53Hg8Gj4WM6fVObhIMtFkrWslFHb2BifNzRYobYCqsHxVpP7vn1ilJ+rOk5tgwPcNj62k9omtk+GzzW0m84xH6a2mUuXqK1Wn6e20W3hY46P8Mf1gfffSW3VsTFq46sPOImY2MeDYy/eWcafV1mLXyiy7Ooj1yL33blc+Hgf+kfv53Ou2oMrjnQ+YfXfAHwYwCEA95vZoWs9nhBia9nIe/Y7ALzi7q+5ewPA1wDctzluCSE2m40E+168PZHize7Y2zCzo2Z23MyOt1v8FkgIsbVs+W68ux9z9yPufiRf0Oa/EP1iI9F3Fp20xyvs644JIa5DNrIb/wMAB83sJnSC/GMA/ll8igEoBS2lUngcANqNenDcnb8tyEd0i0aNz2tEXv5KlbB8ZRn33Vsj1GbZKLXVlrhUdnp2htpefzlsazVfpnPg/FzlMn+KZF6jtnft2hMcnyteoHNGB7n09r47/yG1tSLSoRv5n9EZgEUk0SwyM4vt8Eel4PD5jOy4A4BnTDHgc6452N29ZWafBPBn6Ehvj7j7C9d6PCHE1rIhnd3dvwPgO5vkixBiC9GOmRCJoGAXIhEU7EIkgoJdiEToadZbu51h/vJy2NZo0nmFfFgqM+MJC0PDg9RWLW+jtsvTDWqbaU4Hx7MWl95Ov8qTRbLsdWqrrfD0jnKJP7bJHeGEl8EBLmuNjIxSW6UcTv4BAG/x9V+8vBQc33NgIjgOAJdnuSz3/DNPU1t5ZAe1jWwPJw2NjfGEnHabZ/O121y2tVh+ZiSbEpHnMYOpg7Hy/7qyC5EICnYhEkHBLkQiKNiFSAQFuxCJ0NPd+CzLsLy8ErQ1lvkuZ3UgvNu9fTsvp9Ss8d3s6XNhRQAAGpFd8PnZ8Dz3SA03vrEbrQtXLPDyWI0S370tFuaC4yv1cDIRAMwtzFLb1EXuYy6y9Vt9dzgBaGiMKyF5oroAwNL8HJ8XUQxOv/pKcHz0PYfpnHKRP2aPJKfESl2xMlKxebE5zBSZoiu7EKmgYBciERTsQiSCgl2IRFCwC5EICnYhEqGn0lsuZyiVwjJVEQN0Xpt0XLk8y+WkIqnrBQArC3xebTmilbXCkkwGPieLJDm0WzzpplHniUGLi4vUNrc0Fxwfm+AdVUZHR6lt99jfqg7+N5TKPCGnRi4jlxbn6JzxoTL3Y89+ahse5hLs7Gy4Bur0FK+NeuDAAWqL93GK2KKdysi8yHOHHS5WW09XdiESQcEuRCIo2IVIBAW7EImgYBciERTsQiRCT6U3d8Db4deXXJ67UlsJS1S12gKds63KpbxmK9IaqsEzrzJSfyzapieihbjzDLtY9lJM/KmQNlp794Vr0wHADTfdTG23/vi7qa3F3UeTZNk1M/7A6k3+yBYWeC2/6ki4zhwADFbD8uDUuSk6Z+9evlYDFS4PItKOLGfXcF2NlqaLiWxhNhTsZnYKwAKANoCWux/ZyPGEEFvHZlzZf9rdw2VXhRDXDXrPLkQibDTYHcB3zewpMzsa+gMzO2pmx83seNa++vrYQojNYaO38Xe5+1kz2wngcTP7f+7+vdV/4O7HABwDgGIlr2gXok9s6Mru7me73y8A+CaAOzbDKSHE5nPNV3YzqwLIuftC9+efB/AfYnM8A2qksKRZuBAlAOQK4dcky3H3SyVeNLBZ55pRgWTlAbxA5OJijc/JcT/y+VgqVEzG4TdInoXnLS2G2zEBQKPOs+8ycjwgrgy98fqp4Pj5M/wx337bj1Hbvt08660dkbxK1XDbq5npi3TO2be4LHfg5huoLdb+6XrYHtvIbfwkgG92K2MWAPx3d//TTfFKCLHpXHOwu/trAN6zib4IIbaQ/t9bCCF6goJdiERQsAuRCAp2IRKhx1lvjkYzXEjRMy7klMvhTKNiJFNusMr7fyHjxRzduQzFWnlt28bPVavxc7UjnyjMcQUQsdfoWi2cbXbmzBk6Z/vOSWpz5z7mI9Ln+fPhdIkCuEw2GOmxduvNPDNvIvLcyefDCzk2Nk7nXLrEUz12TW6ntpFh3scusow9Q1d2IRJBwS5EIijYhUgEBbsQiaBgFyIRerobbznDQKUStK2s8GSSLAu3V8py/LUqi6Rp5Er8YVshsntOdvFL5XDdNwCo1/nuMyI703D+2GI7u06SZGo1vr4zMzPUViO15ACgXOI+FgpkjZtc7Zibu0xtMzOz1LaP1AYEACuGJZRKpJbcUoOv1bmpc9Q2PMTbUMXryYUxJv9cI7qyC5EICnYhEkHBLkQiKNiFSAQFuxCJoGAXIhF6K73BkC+EExMGBsKSHMCTGeoRiWRhaZnaSsVwSyAAKJR5Boq3wtLb0vIindOKyEJRCS3SNyqWnGKkrl0xkmQSk+UaDS69DVT4OpJ/GZoNXv9vaYm382o2uY+tdkQuzYVl0ZgSNjDAW4fNzc1R28JCpB1ZJEmG1fmT9CaEuCYU7EIkgoJdiERQsAuRCAp2IRJBwS5EIvS+Bh1pNRRrM8Rssbp1rcjxKkT+AxB/+cuFj5kvcImkHTmeR9oFmfGJuUi2X6kSfmzlQZ7lFcs4vHjxErUNDPIsr6WV+eB4MdK6qlSJtOxqcSk1KsshfEyLyJfl2PMjooa99dZb1Db8Y3ytNltiY6x5ZTezR8zsgpmdXDU2bmaPm9nL3e9jW+umEGKjrOc2/vcB3POOsQcBPOHuBwE80f1dCHEds2awd/utv7O6wX0AHu3+/CiAj2yuW0KIzeZa37NPuvuVvrbn0OnoGsTMjgI4CvCPcgohtp4N78Z754PadLfD3Y+5+xF3P5LLKdiF6BfXGuznzWw3AHS/X9g8l4QQW8G13sZ/G8AnAHy2+/1b65vmcCKJ1VZ4dhXLeqsO8eykmHRVX16htkIk26xQCZ+vbZHCkZGCjTEf83kuQ+Ujba8KhfBNVinyFqpa5rYS+FpVC/yx3bQ7LNAcuu02OqcYkbyySMuumPTmRjLzItJb0/n/s1jgxUXnZsNyIwBcnuO2sfHR4LhH/LgW1iO9fRXA/wFwq5m9aWYPoBPkP2dmLwP42e7vQojrmDWv7O5+PzF9aJN9EUJsIfq4rBCJoGAXIhEU7EIkgoJdiEToadZbzgzVgbB00Vjh0gpTtpokgw4ALWwJANbiRQ/LFsm8In5UK1U6Z3LfOLUVCvy1tlji/g9E+pQVyeebdk1up3Mmto9Q2513Haa27RP8se2vhBdrYtc+Omch8hyYmZmmtnakiKXlw30CY7QjkmjBeMjkIvLmhWneT6+6bShsiEhvbSIdZhFJUVd2IRJBwS5EIijYhUgEBbsQiaBgFyIRFOxCJEJPpbcscywvhTOUcsalpmqVZLcVIn3UwDOhto9xyeiW3fupjWVDbdvGe55NjPJCg+VIgcVymdu2MakGwGA5LAOObuPymjuXp3aNcf/HhvnjvkAem7e4XJpl3I+YrdmMSLClsCwXq63QbnP5qt3mMl+hzDPiliN9CWvNcPZgscgl1mYr7GOsf6Cu7EIkgoJdiERQsAuRCAp2IRJBwS5EIvS+/VMjvKuatfnuKGv/NFSt0DmVIb6TOT7IH/bBG/lO/ejwaHA8lrQyOMh31UuliC2yG18sxmzhNclHkjSaPP8EjSXedqle5LvPjXp499kqfOe8HWnn1W5zJ+uRne4yPV8kUSqSCNOO9POyIrdlxtWEy8uzwfHREVqhHc4StiKtpHRlFyIRFOxCJIKCXYhEULALkQgKdiESQcEuRCL0VHoDjCa8ZLw3JOqkhVJrjksuw5HEGovIYdbmUlPRwgkoxci5ECmB5hHJqxWRoTIiXwJAuxhu11QqR+a0eUJRk0hoAFBfichy9bAfWWROKyKHNSMJNI2I9GaN8HMnX+BPfdZuDAByLS5tWUSWazYXqe38xfBaDQ3xJCQDT4ZirKf90yNmdsHMTq4ae8jMzprZs92ve6/6zEKInrKe2/jfB3BPYPwL7n64+/WdzXVLCLHZrBns7v49ALwOrhDiR4KNbNB90sxOdG/zw/15AZjZUTM7bmbHPZZZL4TYUq412L8E4ACAwwCmAHyO/aG7H3P3I+5+xCKf2xVCbC3XFOzuft7d297pFv9lAHdsrltCiM3mmqQ3M9vt7lPdXz8K4GTs76/gANpEAcpFMo1YxlY+x98WNFa4nFRbDssxAJBF6rExeTDWYMgiLXycZPMBQC4iReYj74YyhNcqi3gZq0FXa4RlIQBoX+ba4UotLLEtZ+EMLwBoF3gWI8uiA+LSW55Idu2M+16IyHLGepEByLciWW9t7uP0hbeC47u285ZdI8PhWokG7t+awW5mXwVwN4DtZvYmgN8GcLeZHUYnfk8B+NW1jiOE6C9rBru73x8YfngLfBFCbCH6uKwQiaBgFyIRFOxCJIKCXYhE6GnWm8GQs/ApY5+3KRbDc4ol/lqVy3EJIsv4vIUVnl1l80SGKnBZpVSJSIo5vvzukUw658dkyWGzl/gnnpdWLlPbQCRDcHx0G7XNzZAsrzLP5BrZsYfaYp++rNX4+hfYgkSeb1mkxVOs/ZNFDurOJczTr78YHF+e5zLl+NjNwfGlpQU6R1d2IRJBwS5EIijYhUgEBbsQiaBgFyIRFOxCJEKPC046ciwrJ6K91RthucMjhQErJS7VLDf5uZ576Ryftxy2DY2O0DmTu3dQW6HAZa3BwSq1ecaz1Oq1sG3q9XBmFQDMXJ6nttLgILVt38aLKLZa4ayyeoNLgJXBOWobneAZYHv2RzLRlpeC441Idlg5i/QdpBZgscLXo2y80ObKbFhie/yZ43ROLRd+7lyavUjn6MouRCIo2IVIBAW7EImgYBciERTsQiRCjxNhgAKrkRapq+Zsd7TNd00bNV5jrDo5Sm17d+2ltgzl4Pi2Mb5TXB3mySLFYonahoZ4e598gasQJXLM9xy6lc6ZWwjvWAPA8DhXEwbAd5gXFsK7wqffmAqOA8DcHE8WqVb5dalY4M+DSzNzwfGlJk+eGclzlaQVqUGX5biPw0WeQNOIJF8xdu4KV28vkKQxQFd2IZJBwS5EIijYhUgEBbsQiaBgFyIRFOxCJMJ6OsLsB/AHACbR6QBzzN2/aGbjAP4IwI3odIX5ZXfnRbPQkd5Y66JY/S5GLtJ3KWtxiWTvrt3Udted76e2ejPsvJW4THbufKT22xKXvGK1zioDA9TmA+FF2TfBfSwN8KdBpcpbMu2I1KebLlwKjs9M83/a/n03UFu1yh9zKc/X6sx0WGJbXObJP4185BoYqSmIiGSXi8zLPPzcL+X42k8M7wyOF/Ibk95aAH7D3Q8B+ACAXzezQwAeBPCEux8E8ET3dyHEdcqawe7uU+7+dPfnBQAvAtgL4D4Aj3b/7FEAH9kiH4UQm8BVvWc3sxsBvBfAkwAmV3VyPYfObb4Q4jpl3R+XNbMhAF8H8Gl3n7dVxSbc3c0s+IbWzI4COAoAuVhxeCHElrKuK7uZFdEJ9K+4+ze6w+fNbHfXvhvAhdBcdz/m7kfc/Ujko8NCiC1mzfCzziX8YQAvuvvnV5m+DeAT3Z8/AeBbm++eEGKzWM9t/J0APg7geTN7tjv2GQCfBfCYmT0A4DSAX17rQDnLYbgSzspqRKQmJ7f/lRKXOooRWagceTuxMMelslwpLP8MDYUzkADg/Pnz1HbhQvBmCAAwMsLr2g1WeX268YnwvMUSl3FaTZ4huNiqU9uoRVpUNcP/z4LxTL/Ls1yKHCjxeS+ePEltr14IS2/5SPZapc3lwWyQP+Z8hdfrO++RLMxqWNKlLbQATP/fE8HxlUWeObhmsLv7X4F3xvrQWvOFENcHehctRCIo2IVIBAW7EImgYBciERTsQiRCTwtOFgs5TE4MB23NSEujlodlknwkO6lc4LYhIv8BQCVSBLJOqmJmGZdxCgW+xJOT/BPG7Yj804xIZRnxsUmkMCAuvY2N8Wy5nHNZrlIMy5TLvM4jfvBMWE4CgJ/6ycPUNnWetzz6/g/Cstyu8XE6Z7zCpc3ZjBeHbBf4c2dkiEvB/+DIu4PjN+y7mc5p1UmmXPFpOkdXdiESQcEuRCIo2IVIBAW7EImgYBciERTsQiRCT6W3fN6wbZhIELlwH7WOLfyalEXkumK4lgYAoBxJ1spFes7VV8IS1fA4X8ZY4cjp6XBRRgCI1fkolfhaZdlEcLxe537kIycbLPNCj1mdZ2U122FZbnGFZ7ZNTU9T28IyP9fBW/ZQW7kaXitfjkiR81yKrESKMlxc5hlnuyJFTieJrRopZFothrMbByr/i87RlV2IRFCwC5EICnYhEkHBLkQiKNiFSISe7sZ7DshIjkE+z3eEmS3L+Jyc89ex+cUFanvhxPPUtnP//uB4o85bCZUKfOu/Wua76rH1IFW7AQCs9F6xyHeY5y/x9fjhxcvUdttN26gta4Z3ptst7kepyJNFYrv4w0M8oej2W28Mjk+d4UrIuRVeh7C2wHfcWd09ANg+xhNvBsvhXfdCjodnMwv74SRpDNCVXYhkULALkQgKdiESQcEuRCIo2IVIBAW7EImwpvRmZvsB/AE6LZkdwDF3/6KZPQTgXwC4UgDsM+7+ndixMgOWi+HkFXMuWxSI0hTrPlSgTWx4kgYArCxyGW3P/nCSSWuZ10DbtyNccw8AJqo8yaRR58XaShX+bxurhl+/Bwe5JHPxDJfXps/w9Th00+3U1qqHJbahMl+PPbvC0iYANOq89lurxR+bESmqOMBbNS3nZqntpVdfo7ZSpLbhyiKXDpu18HPfCzzRyxG2Zc7nrEdnbwH4DXd/2syGATxlZo93bV9w9/+6jmMIIfrMenq9TQGY6v68YGYvAti71Y4JITaXq3rPbmY3AngvgCe7Q580sxNm9oiZ8VamQoi+s+5gN7MhAF8H8Gl3nwfwJQAHABxG58r/OTLvqJkdN7PjzQZ/PyGE2FrWFexmVkQn0L/i7t8AAHc/7+5t73wY98sA7gjNdfdj7n7E3Y8US5EdNSHElrJmsJuZAXgYwIvu/vlV46tr6XwUQLj1hhDiumA9u/F3Avg4gOfN7Nnu2GcA3G9mh9GR404B+NW1DpQvGEYmwnKTR+STIsn+yRmfU448skKDy3wV53cf1gpnGrUWLvBzeYXaqgVuG4xkxHmkUN7K4lxwPB9pUVUqcJlyYJDbLs7wzLGLM2HJbv+Nt9A5QztvoLb52Te5bYm/PTx1+nRwfGGJZ6+1I9mUO/fsoLYbb3gXtU3u5PNWVsK+FCItzHKk9ZlHaiiuZzf+r4CgaB3V1IUQ1xf6BJ0QiaBgFyIRFOxCJIKCXYhEULALkQg9bv8EjIwSY4tLXkx6y+ciRSojWW82z/WJSqQN1eWZcDZUpcILJa6scFno7IVlaot0J8LOvVzGue1gWP6JLBUGBkkVUACLA7zt0osvn6K2edIqa2+Bt0GyIs9EW6nxQpXPnHiJ2p59/pXwuSKXubt/+oPUdtvtt1HbUJX7Xy7xjDhGlkV0NEZkiq7sQiSCgl2IRFCwC5EICnYhEkHBLkQiKNiFSISeSm85OEq5sISSWUQqa4cztrzN5bp6PZIx1ORSWeyYedI/rs4TypBl/HilAV58sUaKEAJAvcn1FVYfJG9cXsuX+FpVtvHssBde4ploc0vhop4LTV6wcdfuPdT2/AtcXptf4PJgdSS8xgdvuZnOuf32v0dt3ub/l2aLF8UEIk8SIhNnWeRaTNLbYmKdruxCJIKCXYhEULALkQgKdiESQcEuRCIo2IVIhN5mveWKGC3tDNo81riNyWERaWLFuEQyvcCzzd568zy1LS2E+6/lIq57JL1qYGAbtRVK/F9zaZH7f2l6LjheNC7zVQa5j5bnffFen1qgtgaRS5t+ls6ZX+DHq9f5/3PPPt6g6O8fORwcv/0Ql9fmZ+eordHifpQK/IngEenNiaQbSVSER61hdGUXIhEU7EIkgoJdiERQsAuRCAp2IRJhzd14M6sA+B6Acvfv/9jdf9vMbgLwNQATAJ4C8HF3j2UCIIcShgr7g7Zmm9dqq5H6Y0uRBIjLZOccABYj7YJQ4HXE5lfCLY0uRXZvm853TQu5Ge5HJKUh1vYqz2weqYGW48ezPN999owfs1QO20rLPLFmcJC3w7rlIG8bte9dfDd++/hocHzmEm/Z1arz50c+oq7EWi/FVBkny5+LpbUYsW2wBl0dwM+4+3vQac98j5l9AMDvAPiCu98CYBbAA+s4lhCiT6wZ7N7hyiW02P1yAD8D4I+7448C+MhWOCiE2BzW25893+3gegHA4wBeBTDn7lfu8d4EwO+lhBB9Z13B7u5tdz8MYB+AOwD8+HpPYGZHzey4mR1fXuGfxhJCbC1XtRvv7nMA/hLATwIYNbMrG3z7AAQ/B+nux9z9iLsfGRzgDRiEEFvLmsFuZjvMbLT78wCAnwPwIjpB/4vdP/sEgG9tkY9CiE1gPYkwuwE8amZ5dF4cHnP3/2lmfw3ga2b2nwA8A+DhtQ7UbjvmLoVljVqNSzIZqftlOV5LbnhknNoGh7kcNjTEJbscwr5XBvkdS73FZZx2m+skTI7pzOPHzDy8Vu1IKyF3fjyPSIcRE1qtsFzaci6vTUZq0N10Y7itFQBUB7lcmrXCTtYiteRyEZksVknOs8iCRGosIgsfNRfR8nLkeB6Zs2awu/sJAO8NjL+Gzvt3IcSPAPoEnRCJoGAXIhEU7EIkgoJdiERQsAuRCBbbqt/0k5ldBHC6++t2ANM9OzlHfrwd+fF2ftT8uMHdd4QMPQ32t53Y7Li7H+nLyeWH/EjQD93GC5EICnYhEqGfwX6sj+dejfx4O/Lj7fyd8aNv79mFEL1Ft/FCJIKCXYhE6Euwm9k9ZvZDM3vFzB7shw9dP06Z2fNm9qyZHe/heR8xswtmdnLV2LiZPW5mL3e/j/XJj4fM7Gx3TZ41s3t74Md+M/tLM/trM3vBzD7VHe/pmkT86OmamFnFzL5vZs91/fj33fGbzOzJbtz8kZlFSgYHcPeefgHIo1PD7mYAJQDPATjUaz+6vpwCsL0P5/0ggPcBOLlq7L8AeLD784MAfqdPfjwE4N/0eD12A3hf9+dhAC8BONTrNYn40dM1Qaen41D35yKAJwF8AMBjAD7WHf9dAL92Ncftx5X9DgCvuPtr3qkz/zUA9/XBj77h7t8D8M6i8fehU6UX6FG1XuJHz3H3KXd/uvvzAjqVkPaix2sS8aOneIdNr+jcj2DfC+DMqt/7WZnWAXzXzJ4ys6N98uEKk+4+1f35HIDJPvrySTM70b3N3/K3E6sxsxvRKZbyJPq4Ju/wA+jxmmxFRefUN+jucvf3AfgwgF83sw/22yGg88qOaG+PLeVLAA6g0xBkCsDnenViMxsC8HUAn3b3t7Xf6eWaBPzo+Zr4Bio6M/oR7GcBrO4BRSvTbjXufrb7/QKAb6K/ZbbOm9luAOh+5/2JthB3P999omUAvowerYmZFdEJsK+4+ze6wz1fk5Af/VqT7rnncJUVnRn9CPYfADjY3VksAfgYgG/32gkzq5rZ8JWfAfw8gJPxWVvKt9Gp0gv0sVrvleDq8lH0YE3MzNApWPqiu39+lamna8L86PWabFlF517tML5jt/FedHY6XwXwb/vkw83oKAHPAXihl34A+Co6t4NNdN57PYBOg8wnALwM4M8BjPfJjz8E8DyAE+gE2+4e+HEXOrfoJwA82/26t9drEvGjp2sC4CfQqdh8Ap0Xln+36jn7fQCvAPgfAMpXc1x9XFaIREh9g06IZFCwC5EICnYhEkHBLkQiKNiFSAQFuxCJoGAXIhH+P6f3DiEKzIChAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# We select a random index.\n",
        "idx = np.random.randint(0, 5000)\n",
        "\n",
        "# We display one of the images.\n",
        "plt.imshow(X_train[idx])\n",
        "plt.title(class_names[np.argmax(Y_train[idx])])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r64cIYAxiCvJ",
        "outputId": "1a61832c-48ef-4902-fd04-91b7b533d543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 16, 16, 64)        13376     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 16, 16, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 128)       131200    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 13, 13, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 13, 13, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 10, 10, 128)       262272    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 10, 10, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 10, 10, 128)       0         \n",
            "                                                                 \n",
            " global_max_pooling2d (Globa  (None, 128)              0         \n",
            " lMaxPooling2D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 408,257\n",
            "Trainable params: 407,617\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7ff9fe4bbc10>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "latent_dim  = 128\n",
        "image_size  = 32\n",
        "num_classes = 10 \n",
        "\n",
        "def get_discriminator():\n",
        "  # Create the model discriminator.\n",
        "  discriminator = Sequential(name=\"discriminator\")\n",
        "\n",
        "  # üí° >>> Now the discriminator input will increment the number\n",
        "   # >>> of feeds to add the One-hot vector\n",
        "  discriminator.add(Input(shape=(32, 32, 3 + num_classes)))\n",
        "  \n",
        "  discriminator.add(Conv2D(64, kernel_size=4, strides=2, padding=\"same\"))\n",
        "  discriminator.add(BatchNormalization())\n",
        "  discriminator.add(LeakyReLU(alpha=0.2))\n",
        "  \n",
        "  discriminator.add(Conv2D(128, kernel_size=4))\n",
        "  discriminator.add(BatchNormalization())\n",
        "  discriminator.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  discriminator.add(Conv2D(128, kernel_size=4))\n",
        "  discriminator.add(BatchNormalization())\n",
        "  discriminator.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  discriminator.add(GlobalMaxPooling2D())\n",
        "  discriminator.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "  discriminator.summary()\n",
        "  return discriminator\n",
        "\n",
        "get_discriminator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkobzNyqpgfa",
        "outputId": "04dae11a-c080-4218-8f22-460e380ebc8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 1152)              160128    \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 3, 3, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 8, 8, 128)        262272    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 18, 18, 256)      524544    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 18, 18, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 18, 18, 256)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 36, 36, 512)      2097664   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 36, 36, 512)      2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 36, 36, 512)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 3)         38403     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,086,595\n",
            "Trainable params: 3,084,803\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7ff9c0010d00>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "def get_generator(latent_dim=128):\n",
        "\n",
        "  generator = Sequential(name=\"generator\")\n",
        "  \n",
        "  # üí° >>> Now the input receives the latent vector and the\n",
        "  # concatenated One-hot vector.\n",
        "  generator.add(Input(shape=(latent_dim + num_classes)))\n",
        "  \n",
        "  generator.add(Dense(3 * 3 * latent_dim))\n",
        "  generator.add(Reshape((3, 3, latent_dim)))\n",
        "\n",
        "  generator.add(Conv2DTranspose(128, kernel_size=4, strides=2))\n",
        "  generator.add(BatchNormalization())\n",
        "  generator.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  generator.add(Conv2DTranspose(256, kernel_size=4, strides=2))\n",
        "  generator.add(BatchNormalization())\n",
        "  generator.add(LeakyReLU(alpha=0.2))\n",
        "  \n",
        "  generator.add(Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"))\n",
        "  generator.add(BatchNormalization())\n",
        "  generator.add(LeakyReLU(alpha=0.2))\n",
        "  \n",
        "  generator.add(Conv2D(3, kernel_size=5, strides=1, padding=\"valid\", activation=\"sigmoid\"))\n",
        "\n",
        "  generator.summary()\n",
        "  return generator\n",
        "\n",
        "get_generator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9CWAYdvsrdca"
      },
      "outputs": [],
      "source": [
        "class GAN(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, discriminator, generator, latent_dim):\n",
        "      super(GAN, self).__init__()\n",
        "      # We save the discriminator and the generator.\n",
        "      self.discriminator = discriminator\n",
        "      self.generator     = generator\n",
        "      self.latent_dim    = latent_dim\n",
        "\n",
        "  def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "    super(GAN, self).compile(d_optimizer, g_optimizer, loss_fn)\n",
        "    self.d_optimizer = d_optimizer\n",
        "    self.g_optimizer = g_optimizer\n",
        "    self.loss_fn = loss_fn\n",
        "  \n",
        "  def train_step(self, data):\n",
        "\n",
        "    # üí° >>> Now the data is the input and the labels.\n",
        "    real_images, one_hot_labels = data\n",
        "\n",
        "    # üí° >>> We format the One-hot vector to image size.\n",
        "    image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
        "    image_one_hot_labels = tf.repeat(image_one_hot_labels, repeats=[image_size * image_size])\n",
        "    image_one_hot_labels = tf.reshape(image_one_hot_labels, (-1, image_size, image_size, num_classes))\n",
        "\n",
        "    # ----------- DETECTOR TRAINING ------------- #\n",
        "\n",
        "    # Lot Size\n",
        "    batch_size = tf.shape(real_images)[0]\n",
        "\n",
        "    # We generate random vectors as input to the generating network.\n",
        "    random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "     # üí° >>> We add the class info to the input vectors of the generator.\n",
        "    random_latent_vectors = tf.concat([random_latent_vectors, one_hot_labels], axis=1)\n",
        "\n",
        "    # We use the vectors to generate random images. (We decode)\n",
        "    fake_images = self.generator(random_latent_vectors)\n",
        "\n",
        "    # üí° >>> We add the class info to the decoder input images.\n",
        "    fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
        "    real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
        "\n",
        "    # We concatenate them to the set of real images.\n",
        "    combined_images = tf.concat([fake_image_and_labels, real_image_and_labels], axis=0)\n",
        "\n",
        "    # We generate the output for each image (Fake: 1 / Real: 0)\n",
        "    labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n",
        "\n",
        "    # Add random noise to the labels - important trick!\n",
        "    labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "      # Predictions made by the discriminator.\n",
        "      predictions = self.discriminator(combined_images)\n",
        "\n",
        "      # We evaluate the results of the discriminator with the cost function.\n",
        "      d_loss = self.loss_fn(labels, predictions)\n",
        "\n",
        "    # Calculate the gradient with the discriminator error.\n",
        "    grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "\n",
        "    # Update the parameters with the gradients.\n",
        "    self.d_optimizer.apply_gradients(\n",
        "          zip(grads, self.discriminator.trainable_weights)\n",
        "    )\n",
        "\n",
        "    # ----------- GENERATOR TRAINING ------------- #\n",
        "\n",
        "    # We create new vectors to generate random images. (We decode)\n",
        "    random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "    # We create the labels with which to supervise the training of the generator.\n",
        "    misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "    # We train the generator WITHOUT updating the detector!\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "      # üí° >>> We add the class info to the input vectors of the generator.\n",
        "      random_latent_vectors = tf.concat([random_latent_vectors, one_hot_labels], axis=1)\n",
        "\n",
        "      # üí° >>> We generate and add the class info.\n",
        "      fake_images = self.generator(random_latent_vectors)\n",
        "      fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
        "\n",
        "      # We obtain new predictions by passing to the discriminator what is generated.\n",
        "      predictions = self.discriminator(fake_image_and_labels)\n",
        "\n",
        "      # We calculate the error of the generator in its task of confusing the discriminator.\n",
        "      g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "\n",
        "    # Calculate the gradient of the generator.\n",
        "    grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "\n",
        "    # Update the parameters with the gradients.\n",
        "    self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "    return {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EoJiJyFN4bB_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "# üí° >>> We create a personalized callback to visualize the evolution\n",
        "# of the generator after each epoch.\n",
        "class GANMonitor(Callback):\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        for cls in [6, 7]:\n",
        "          random_latent_vectors = tf.random.normal(shape=(3, self.model.latent_dim))\n",
        "          # We always generate vectors of the number 3.\n",
        "          one_hot_vectors = tf.reshape(tf.repeat(to_categorical(cls, num_classes=10)[None,:], repeats=3, axis=0), (3, num_classes))\n",
        "          generated_image = self.model.generator(tf.concat([random_latent_vectors, one_hot_vectors], axis=1))\n",
        "\n",
        "\n",
        "          fig, axs = plt.subplots(1, 3)\n",
        "\n",
        "          for i in range(3):\n",
        "            if generated_image.shape[3] > 1:\n",
        "              fig.axes[i].imshow(generated_image[i,:,:,:])\n",
        "              fig.axes[i].axis(\"off\")\n",
        "            else:\n",
        "              fig.axes[i].matshow(generated_image[i,:,:,0])\n",
        "              fig.axes[i].axis(\"off\")\n",
        "\n",
        "          plt.title(\"frog\" if cls == 6 else \"horse\")\n",
        "          plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fwI7CQW4fQd",
        "outputId": "918ac1ee-5978-46dd-fbce-3553fba01e43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 16, 16, 64)        13376     \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 13, 13, 128)       131200    \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 13, 13, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 13, 13, 128)       0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 10, 10, 128)       262272    \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 10, 10, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 10, 10, 128)       0         \n",
            "                                                                 \n",
            " global_max_pooling2d_1 (Glo  (None, 128)              0         \n",
            " balMaxPooling2D)                                                \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 408,257\n",
            "Trainable params: 407,617\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n",
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 1152)              160128    \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 3, 3, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 8, 8, 128)        262272    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_9 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  (None, 18, 18, 256)      524544    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 18, 18, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_10 (LeakyReLU)  (None, 18, 18, 256)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2DT  (None, 36, 36, 512)      2097664   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 36, 36, 512)      2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_11 (LeakyReLU)  (None, 36, 36, 512)       0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 3)         38403     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,086,595\n",
            "Trainable params: 3,084,803\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.losses import *\n",
        "\n",
        "# We create a GAN with our class.\n",
        "gan = GAN(discriminator=get_discriminator(), generator=get_generator(), latent_dim=latent_dim)\n",
        "\n",
        "# We configure the optimizers of each part...\n",
        "gan.compile(d_optimizer=Adam(learning_rate=0.0001),\n",
        "            g_optimizer=Adam(learning_rate=0.0001),\n",
        "            loss_fn=BinaryCrossentropy())\n",
        "\n",
        "# ...and we give it to train.\n",
        "#gan.fit(train_gen, epochs=1000, callbacks=[GANMonitor()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1dkotSN4fLh",
        "outputId": "ab00e231-fa78-4143-caba-3c5ce9a94d6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n"
          ]
        }
      ],
      "source": [
        "gan.fit(train_gen, epochs=1000, callbacks=[GANMonitor()], steps_per_epoch=100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}